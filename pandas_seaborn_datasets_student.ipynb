{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Examining and Visualizing Data\n",
    "=============================\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<h2>Overview</h2>\n",
    "\n",
    "<strong>Questions:</strong>\n",
    "\n",
    "* How can I use pandas to process data?\n",
    "\n",
    "* How can I visualize relationships between different parts of my data?\n",
    "\n",
    "<strong>Objectives:</strong>\n",
    "\n",
    "* Use pandas and seaborn to load and explore data\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pandas data science library\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/docs/) is a Python library used for data analysis and manipulation. Within the world of data science, it is a ubiquitous and widely used library. If you are learning how to analyze data in Python, it will be almost impossible to avoid pandas. \n",
    "\n",
    "As with any python library, we need to import pandas to use its functions.  A common practice is to abbreviate `pandas` as `pd`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central data structure of pandas is called a DataFrame. Pandas DataFrames work very closely with NumPy arrays and Pandas dataframes are specifically for data which is two dimensional (rows and columns). NumPy arrays, while similar in some ways, can work with higher dimensional data.  Very broadly, NumPy arrays are designed to work with data that is all one data type, whereas Pandas dataframes are designed to work with a variety of data types.\n",
    "\n",
    "Pandas is very powerful. In this session, we'll be learning how to access information in pandas dataframes and how to do some basic manipulation and analysis. We are going to be looking at a dataset which gives information about the elements in the periodic table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pandas dataframe by reading in a CSV file.\n",
    "df = pd.read_csv(\"data/PubChemElements_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially when loading data in, and also at certain points as we're working with it, we'll want to see what our dataframe looks like. You can see a preview of your dataframe using the `.head` function\n",
    "\n",
    "When you preview the dataframe, you will see that the rows are labeled with numbers and the columns are labeled with column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default behavior is to show the first five rows of a dataframe\n",
    "# You can change this by putting a different number in the parenthesis\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.info` function will give information about the columns and the data type of those columns. The data type will become very important later as we work with data more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataframe, we see that the first column, `AtomicNumber` has the data type of `int64`. Here, `int` means `integer` and `64` means `64 bit`.  The `64 bit` refers to the amount of computer memory the variable can occupy. It won't really be important for us. Similarly, `float64` means `64 bit floating point`. These are decimal numbers.\n",
    "\n",
    "The other column names which read `object` are not numeric. They might be strings or they might be something else. \n",
    "\n",
    "The `describe` function can be used on a dataframe to quickly see statistics about columns with numerical data. If you look at the columns that statistics are computed for and compare to the data type shown from `info`, you will see that we only get statistics for columns which had `int64` or `float64` data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information is extremely useful for understanding the data. We can also easily visualize the distribution of each column using Pandas's ``hist`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(figsize=(8,8), edgecolor='black', grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data\n",
    "\n",
    "Pandas dataframes have names for rows (called the \"index\" in Pandas) and columns.\n",
    "\n",
    "Pandas dataframes have rows and columns, you can see how many rows and columns using `.shape`. This will return the shape as `(num_rows, num_columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few methods for accessing information in a Pandas dataframe, but the one that will be most important in this workshop is selecting particular columns of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the atomic number column\n",
    "# It won't show the whole column because it's too long\n",
    "df[\"AtomicNumber\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could also show two columns at once\n",
    "# You can combine with the .head() function to just show the beginning\n",
    "df[[\"Symbol\", \"ElectronConfiguration\"]].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing calculations with pandas: No more `for` loops!\n",
    "\n",
    "Both pandas and NumPy dataframes have the convenient feature that they can do element-wise operations and use something called `broadcasting`. This means that if you are doing something like subtracting a number, multiplying, etc to a column or dataframe of information, it can be done all at once instead of with a `for` loop.  We saw this previously in our NumPy lesson.  \n",
    "\n",
    "Consider if we wanted to calculate the melting point in degrees celsius for all of the elements. Instead of writing a `for` loop that does this, we can just write the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MeltingPoint'] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do this one two columns as well.  In that case, we would have a list of column names instead of just one column name.  This is why there are the double brackets in this notation; the inner brackets are specifying the list of column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['MeltingPoint', 'BoilingPoint']] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save these in new dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"MeltingPointC\", \"BoilingPointC\"]] = df[['MeltingPoint', 'BoilingPoint']] - 273.15\n",
    "\n",
    "#Show the dataframe again to check our our new columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `.apply` method\n",
    "\n",
    "The `.apply` method in pandas is used to apply a function along a row or column of a dataframe.\n",
    "This is useful when you have a custom function that you need to use on every value in a column, but there is not a NumPy or Pandas function for it.\n",
    "\n",
    "For example, we could apply the `len` function to our `Name` column to get the number of letters in the name for each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of letters in name - \n",
    "df[\"Name\"].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<strong>The .apply function</strong>\n",
    "\n",
    "Notice that when we use `.apply`, we write the <strong>name</strong> of the function we want to apply, \n",
    "but we do not <strong>call</strong> the function. \n",
    "If we were to call the `len` function, we would use parentheses `()` with an argument.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RDKit Functions with Pandas DataFrames\n",
    "Using `len` to calculate the number of letters in an atom name is a silly example, but for an example more related to our work with RDKit, let's add some additional atomic data.\n",
    "\n",
    "RDKit has the ability to get information about atoms.\n",
    "We can create a periodic table with `Chem.GetPeriodicTable`, then use associated functions to get information about atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the periodic table\n",
    "periodic_table = Chem.GetPeriodicTable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have a periodic table, we can apply functions from the periodic table to the atoms in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NOuter\"] = df[\"Symbol\"].apply(periodic_table.GetNOuterElecs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h3>Exercise</h3>\n",
    "\n",
    "Use the `tab` key on your periodic table object to check for other values you can calculate for atoms.\n",
    "Pick one to add to your periodic table dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can save a CSV file with our newly calculated values using the `to_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/periodic_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Visualizing data helps in understanding relationships and patterns that might not be apparent from raw data. Here, we will use Seaborn, a statistical visualization library, to create plots from our periodic table dataset. Seaborn is built on top of matplotlib, so if we would like to adjust any of the plots seaborn makes, we can do that through the Matplotlib interface we've used before.\n",
    "\n",
    "We will start with a bar plot to show the ionization energy of elements across different group blocks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df, x=\"NOuter\", y=\"IonizationEnergy\", kind=\"bar\")\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows us periodic trends that we learned about in introductory chemistry. The two highest ionization energy categories correspond to elements with 2 valence electrons and 8 valence electrons, representing filled shells.\n",
    "\n",
    "Seaborn can also allow us to easily create scatter plots to visualize relationships between continuous variables. For example, we can create a scatter plot to show the relationship between ionization energy and atomic radius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x=\"AtomicRadius\", y=\"Electronegativity\", hue=\"GroupBlock\")\n",
    "plt.title('Electronegativity vs. Atomic Radius')\n",
    "plt.xlabel('Atomic Radius')\n",
    "plt.ylabel('Electronegativity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h3>Exercise</h3>\n",
    "\n",
    "Create a few other categorical plots to observe periodic trends.  Note, these instructions are given as y vs. x.\n",
    "\n",
    "1. Electronegativity vs. Group Block as a bar plot.\n",
    "\n",
    "2. Melting Point vs. Group Block as a bar plot.\n",
    "\n",
    "3. Ionization Energy vs. Atomic Number as a scatter plot colored by GroupBlock.\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here.  Add additional cells if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Correlation\n",
    "\n",
    "A common way to visualize relationships between different categories of data categories is with a correlation plot.\n",
    "The correlation matrix provides insights into the relationships between the variables. A correlation value close to 1 indicates a strong positive relationship, while a correlation value close to -1 indicates a strong negative relationship. A correlation value close to 0 indicates no relationship between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr = df.corr(numeric_only=True)\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn can be used to create a heatmap to allow easier examination of the correlation of different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heatmap uses a \"coolwarm\" color scheme where red indicates positive correlation and blue indicates negative correlation between variables. Strongly correlated pairs are represented by darker shades of red, while strongly inversely correlated pairs are represented by darker shades of blue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h3>Final Activity</h3>\n",
    "\n",
    "For our final activity, we will redo the activity we did last week in lab where we created a dataset for the amino acids using RDKit.  This time, instead of writing the data to a file, you will be creating a pandas dataset. You should be able to use Pandas and the `.apply` function to add new columns of data to your DataFrame. \n",
    "\n",
    "The creation of a starting dataframe is done for you in the code cell below.  Add additional code to add the following columns to your dataframe:\n",
    "1. The molecule object created from each SMILES string\n",
    "2. Molecular Weight\n",
    "3. Number of Heavy Atoms\n",
    "4. One or two more molecular descriptors of your choosing\n",
    "\n",
    "Compare and contrast the code - which one do you prefer? \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "\n",
    "# Ensure molecules are rendered in the notebook\n",
    "PandasTools.RenderImagesInAllDataFrames(images=True)\n",
    "\n",
    "filehandle = open(\"data/amino_acids.txt\", \"r\")\n",
    "amino_acid_data = filehandle.readlines()\n",
    "filehandle.close()\n",
    "\n",
    "# Delete the new line character at the end of each smiles string\n",
    "smiles_list = []\n",
    "for smiles in amino_acid_data:\n",
    "    smiles = smiles.strip()\n",
    "    smiles_list.append(smiles)\n",
    "\n",
    "# Initialize the dataframe with the list\n",
    "df = pd.DataFrame(smiles_list, columns=[\"SMILES\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your code to turn in on Canvas\n",
    "\n",
    "Once you are finished with your code for the final activity, collect it all into one cell.  At the top of the cell add the line `%%writefile file_name.txt` but replace `file_name` with a reasonable name for your code file.  Run that cell again and it will save all of your code from just that cell into a plain text file.  This is the file you will turn in on Canvas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
